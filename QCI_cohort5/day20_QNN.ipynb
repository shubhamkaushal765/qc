{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550f4149-10d3-43bf-a220-2729d303bfc1",
   "metadata": {},
   "source": [
    "# Quantum Neural Networks\n",
    "\n",
    "Neural networks and all its specialized architectures such as ConvNets, LSTMs, ResNets, and GANs are part of a broader idea called **differental computing.** Differentible computing is computation carried out using functions with known gradients. These functions have adjustable parameters, and the gradients tell us how to adjust those parameters so that the function performs in a desired manner. \n",
    "\n",
    "> A quantum neural network is any quantum circuit with trainable continuous parameters.\n",
    "\n",
    "In NISQ-era, quantum computing is increasingly being viewed as a form of differential computing. After all, quantum computing is just linear algebra in higher dimensional space.\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "    <img src=\"./images/qnn_example_circuit.webp\", width=\"60%\">\n",
    "    <figcaption>A quantum circuit whose gates have free parameters. These can be trained the same way as a deep neural network.</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "These circuits also go by the name **variational quantum circuits** as they were initially proposed for chemistry problems as **variational quantum eigensolvers (VQEs).**\n",
    "\n",
    "**PennyLane**, a leading software package for quantum machine learning, provides two key features:\n",
    "- Automatic differentiation for quantum circuits\n",
    "- QNode abstraction for building hybrid classical-quantum circuits\n",
    "\n",
    "### Comparison of some available quantum software libraries\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "    <img src=\"./images/qnn_tools.webp\", width=\"50%\">\n",
    "    <figcaption>Comparison of some available quantum software libraries.</figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d2d53-5be9-4e44-8cce-1a363f4cdbc4",
   "metadata": {},
   "source": [
    "## Example Circuit: Training a quantum circuit with PennyLane and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb1b284-1933-416b-9d28-c29f95a5dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import qutip as qt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84b39a-9fea-4594-b19f-02bb10af2183",
   "metadata": {},
   "source": [
    "### Defining the quantum circuit\n",
    "\n",
    "One with Expectation value as output for training, and the other with the quantum state as output foor simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72da161-059d-4d3f-aee7-75bc24ec7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.qubit\", wires=1)\n",
    "\n",
    "# Trainable quantum circuit\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(phi, theta):\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.RZ(phi, wires=0)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit_states(phi, theta):\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.RZ(phi, wires=0)\n",
    "    return qml.state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a691b-aed6-4cb9-ad4d-f88a4528c1da",
   "metadata": {},
   "source": [
    "### Visualizing the Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f718ce-8847-4394-a5ff-0f8c26a12c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = np.random.random(2)\n",
    "# print(qml.draw(circuit)(*params))\n",
    "qml.draw_mpl(circuit)(*params)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4814f56-c2d9-4949-a5bd-d8bdffdeac4a",
   "metadata": {},
   "source": [
    "### Define the cost function to minimize\n",
    "\n",
    "The target defined in the cost function itself, where the polarity changes after every 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853c1427-3c1e-4b40-b8d5-9ce65eb9a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(phi, theta, step):\n",
    "    target = -(-1) ** (step//100)\n",
    "    return torch.abs(circuit(phi, theta)-target)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c384d-101d-4c87-8231-7dd524056b36",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9da3fec-91b9-4e3e-8e7c-66e6a5a33ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = Variable(torch.tensor(1.), requires_grad=True)\n",
    "theta = Variable(torch.tensor(0.5), requires_grad=True)\n",
    "opt = torch.optim.Adam([phi, theta], lr=0.1)\n",
    "\n",
    "states = []\n",
    "\n",
    "for i in range(400):\n",
    "    states.append(circuit_states(phi, theta))\n",
    "    opt.zero_grad()\n",
    "    loss = cost(phi, theta, i)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "states.append(circuit_states(phi, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0acdb-f7ff-45e1-862e-2b65f3e52496",
   "metadata": {},
   "source": [
    "### Making and saving bloch diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24f6250-5717-4966-8183-74cd2cf8d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = qt.Bloch()\n",
    "dst = \"images/bloch/\"\n",
    "paths = []\n",
    "\n",
    "for i in range(len(states)):\n",
    "    b.clear()\n",
    "    s = qt.Qobj(states[i].detach().numpy())\n",
    "    b.add_states(s)\n",
    "    paths.append(f\"{dst}{i}.png\")\n",
    "    b.save(dst + f\"{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf326a-4ba4-4d46-b253-d9ee3f22096f",
   "metadata": {},
   "source": [
    "### Merging all the bloch images into a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d603d04-2bc1-4167-8665-70a5f6e2555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_6852\\2610086272.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(filename))\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 500) to (512, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for filename in paths:\n",
    "    images.append(imageio.imread(filename))\n",
    "writer = imageio.get_writer('images/bloch.mp4', fps=20)\n",
    "for im in images:\n",
    "    writer.append_data(im)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60d24f-7fe2-44ca-87e7-d8d7892a2a10",
   "metadata": {},
   "source": [
    "### Output GIF\n",
    "\n",
    "![bloch](images/bloch.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848cd2f-0700-44fa-bcc1-d114f4150c49",
   "metadata": {},
   "source": [
    "# QNN for IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1e015-59e1-4311-95a3-987edce74c46",
   "metadata": {},
   "source": [
    "### Get the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd6966a-173a-43e3-87a5-37ef27c8893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import pennylane as qml\n",
    "from "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65abbb-a0e8-48c8-8b5d-25fb04a7b80f",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d939ae99-bfdb-4c72-8b53-089950a16d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_data_reduced = True        # Data is reduced to n classes\n",
    "reduced_classes = [1,2,3,7]   # Selected (and sorted) classes\n",
    "\n",
    "# Number of reduced classes\n",
    "reduced_num_classes = len(reduced_classes)\n",
    "\n",
    "# filtering classes\n",
    "def filter_classes(y):\n",
    "    return np.array(list(map(lambda x: x in reduced_classes, y)))\n",
    "train_cond = filter_classes(y_train)\n",
    "test_cond = filter_classes(y_test)\n",
    "x_train, y_train = x_train[train_cond], y_train[train_cond]\n",
    "x_test, y_test = x_test[test_cond], y_test[test_cond]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e07c8-f582-442a-a786-3956e5157482",
   "metadata": {},
   "source": [
    "# Variational Quantum Cirucit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54edf698-61fd-49bd-9a56-04a9a57aa47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 6                  # Number of qubits\n",
    "num_layers = 8                # Number of layers\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires = n_qubits)\n",
    "\n",
    "@qml.qnode(dev, diff_method='adjoint')\n",
    "def circuit(weights, inputs=None):\n",
    "  ''' Quantum QVC Circuit'''\n",
    "\n",
    "  # Splits need to be done through the tensorflow interface\n",
    "  weights_each_layer = tf.split(weights, num_or_size_splits=num_layers, axis=0)\n",
    "  \n",
    "  # Input normalization\n",
    "  inputs_1 = inputs / p_np.sqrt(max(p_np.sum(inputs ** 2, axis=-1), 0.001))\n",
    "\n",
    "  for i, W in enumerate(weights):\n",
    "    # Data re-uploading technique\n",
    "    if i % 2 == 0:\n",
    "      MottonenStatePreparation(inputs_1, wires = range(n_qubits))\n",
    "    \n",
    "    # Neural network layer\n",
    "    StronglyEntanglingLayers(weights_each_layer[i], wires=range(n_qubits))\n",
    "  \n",
    "  # Measurement return\n",
    "  return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcca16f4-3992-4c70-b32d-86ae6e09dcaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to KerasLayer: {'dynamic': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Model  \u001b[39;00m\n\u001b[0;32m      4\u001b[0m input_m \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m n_qubits,), name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m keras_1 \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mqnn\u001b[38;5;241m.\u001b[39mKerasLayer(circuit, weight_shapes, output_dim\u001b[38;5;241m=\u001b[39mn_qubits, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)(input_m)\n\u001b[0;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(num_classes_q, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)(keras_1)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Model creation\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\_env_qml_\\Lib\\site-packages\\pennylane\\qnn\\keras.py:324\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, qnode, weight_shapes, output_dim, weight_specs, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_specs \u001b[38;5;241m=\u001b[39m weight_specs \u001b[38;5;28;01mif\u001b[39;00m weight_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# no point in delaying the initialization of weights, since we already know their shapes\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\_env_qml_\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to KerasLayer: {'dynamic': True}"
     ]
    }
   ],
   "source": [
    "weight_shapes = {\"weights\": (num_layers,n_qubits,3)}\n",
    "\n",
    "# Model  \n",
    "input_m = tf.keras.layers.Input(shape=(2 ** n_qubits,), name = \"input_0\")\n",
    "keras_1 = qml.qnn.KerasLayer(circuit, weight_shapes, output_dim=n_qubits, name = \"keras_1\")(input_m)\n",
    "output = tf.keras.layers.Dense(num_classes_q, activation='softmax', name = \"dense_1\")(keras_1)\n",
    "\n",
    "# Model creation\n",
    "model = tf.keras.Model(inputs=input_m, outputs=output, name=\"mnist_quantum_model\")\n",
    "\n",
    "# Model compilation\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01) ,\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ad64b-768f-46af-a62b-931afac33ed1",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Medium Article - Nathan Killoran, Josh Izaac](https://medium.com/xanaduai/training-quantum-neural-networks-with-pennylane-pytorch-and-tensorflow-c669108118cc)\n",
    "- [Medium - Hybrid QNN for reduced MNIST data](https://towardsdatascience.com/hybrid-quantum-neural-network-for-reduced-mnist-data-840897ad08a)\n",
    "- [Q-munity - Intermediate QNN](https://www.qmunity.tech/tutorials/quantum-neural-networks)\n",
    "- [QNN - A Practical Approach - Piotr Gawron](https://conference.ippp.dur.ac.uk/event/929/attachments/3968/4559/piotr_gawron_quantum_neural_networks.pdf)\n",
    "- [QNN Dropout - PennyLane Tutorial](https://pennylane.ai/qml/demos/tutorial_quantum_dropout/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a15ca-c3cc-48db-8d24-f7dcda81631b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_env_qml_",
   "language": "python",
   "name": "_env_qml_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
